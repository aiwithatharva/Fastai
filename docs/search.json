[
  {
    "objectID": "Is_it_a_tennis_Creating_a_model_from_your_own_data.html#is-it-a-tennis",
    "href": "Is_it_a_tennis_Creating_a_model_from_your_own_data.html#is-it-a-tennis",
    "title": "",
    "section": "Is it a tennis?",
    "text": "Is it a tennis?\n\n#NB: Kaggle requires phone verification to use the internet or a GPU. If you haven't done that yet, the cell below will fail\n#    This code is only here to check that your internet is enabled. It doesn't do anything else.\n#    Here's a help thread on getting your phone number verified: https://www.kaggle.com/product-feedback/135367\n\nimport socket,warnings\ntry:\n    socket.setdefaulttimeout(1)   # Sets global timeout time of 1 sec, ie if socket operation is not complteted in 1 sec then error will be raised.\n    # if set to around 0.01 in colab server it give timeout error since the time is too less for socket operation.\n    socket.socket(socket.AF_INET, socket.SOCK_STREAM).connect(('1.1.1.1', 53)) # This will use AF_INET which is same as IPV4, SOCK_STREAM means TCP.\nexcept socket.error as ex:\n    # print(\"Original exception :\", ex)\n    raise Exception(\"STOP: No internet. Click '&gt;|' in top right and set 'Internet' switch to on\")\n# We cached the error here but did not printed it where as we raise a custom Exception.\n\n::: {#cell-3 .cell _kg_hide-input=‘true’ _kg_hide-output=‘true’ execution=‘{“iopub.status.busy”:“2022-08-15T19:54:58.581817Z”,“iopub.execute_input”:“2022-08-15T19:54:58.582154Z”,“iopub.status.idle”:“2022-08-15T19:55:20.002673Z”,“shell.execute_reply.started”:“2022-08-15T19:54:58.58212Z”,“shell.execute_reply”:“2022-08-15T19:55:20.001747Z”}’ trusted=‘true’ outputId=‘0b4b8a64-b932-4861-e183-ca77133bd6c0’ execution_count=2}\n# It's a good idea to ensure you're running the latest version of any libraries you need.\n# `!pip install -Uqq &lt;libraries&gt;` upgrades to the latest version of &lt;libraries&gt;\n# NB: You can safely ignore any warnings or errors pip spits out about running as root or incompatibilities\nimport os\niskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '') #if kernel run type is not found it will return second arguemnt\n\nif iskaggle:\n    print(\"It is Kaggle !!\")\n\n!pip install -Uqq fastai # -Uqq refers to upgrade extra quitely\n!pip install duckduckgo_search==6.2.6\n\nCollecting duckduckgo_search==6.2.6\n  Downloading duckduckgo_search-6.2.6-py3-none-any.whl.metadata (24 kB)\nRequirement already satisfied: click&gt;=8.1.7 in /usr/local/lib/python3.10/dist-packages (from duckduckgo_search==6.2.6) (8.1.7)\nCollecting primp&gt;=0.5.5 (from duckduckgo_search==6.2.6)\n  Downloading primp-0.5.5-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\nDownloading duckduckgo_search-6.2.6-py3-none-any.whl (27 kB)\nDownloading primp-0.5.5-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/3.0 MB ? eta -:--:--   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 3.0/3.0 MB 103.5 MB/s eta 0:00:01   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.0/3.0 MB 60.6 MB/s eta 0:00:00\nInstalling collected packages: primp, duckduckgo_search\nSuccessfully installed duckduckgo_search-6.2.6 primp-0.5.5\n\n:::\nIn 2015 the idea of creating a computer system that could recognise tenniss was considered so outrageously challenging that it was the basis of this XKCD joke:\nBut today, we can do exactly that, in just a few minutes, using entirely free resources!\nThe basic steps we’ll take are:\n\nUse DuckDuckGo to search for images of “tennis photos”\nUse DuckDuckGo to search for images of “badminton photos”\nFine-tune a pretrained neural network to recognise these two groups\nTry running this model on a picture of a tennis and see if it works."
  },
  {
    "objectID": "Is_it_a_tennis_Creating_a_model_from_your_own_data.html#step-1-download-images-of-tenniss-and-non-tenniss",
    "href": "Is_it_a_tennis_Creating_a_model_from_your_own_data.html#step-1-download-images-of-tenniss-and-non-tenniss",
    "title": "",
    "section": "Step 1: Download images of tenniss and non-tenniss",
    "text": "Step 1: Download images of tenniss and non-tenniss\n::: {#cell-7 .cell _kg_hide-input=‘true’ execution=‘{“iopub.status.busy”:“2022-08-15T20:17:04.164811Z”,“iopub.execute_input”:“2022-08-15T20:17:04.165128Z”,“iopub.status.idle”:“2022-08-15T20:17:04.171Z”,“shell.execute_reply.started”:“2022-08-15T20:17:04.165074Z”,“shell.execute_reply”:“2022-08-15T20:17:04.170146Z”}’ trusted=‘true’ execution_count=3}\nfrom duckduckgo_search import DDGS # previous function is depreciated this is the new one.\nfrom fastcore.all import *\n\ndef search_images(term, max_images=30):\n    print(f\"Searching for '{term}'\")\n    return L(DDGS().images(term, max_results=max_images)).itemgot('image')\n    #L before just right to L is a list type in fastai, DDGS is object has a functino images with input term \"term\" and max_results argument giving number of images to give.\n    # from each item in item itemgot('image') will retrieve image key whose value is url\n:::\nLet’s start by searching for a tennis photo and seeing what kind of result we get. We’ll start by getting URLs from a search:\n\n#NB: `search_images` depends on duckduckgo.com, which doesn't always return correct responses.\n#    If you get a JSON error, just try running it again (it may take a couple of tries).\nurls = search_images('tennis photos', max_images=1)\nurls[0]\n\nSearching for 'tennis photos'\n\n\n'https://images.wallpapersden.com/image/download/rafael-nadal-tennis-tennis-player_Z2ZrbmmUmZqaraWkpJRoZWVlrWdlZWU.jpg'\n\n\n…and then download a URL and take a look at it:\n\nfrom fastdownload import download_url\ndest = 'tennis.jpg'\ndownload_url(urls[0], dest, show_progress=False)\n\nfrom fastai.vision.all import *\nim = Image.open(dest)\nim.to_thumb(256,256)\n\n\n\n\n\n\n\n\nNow let’s do the same with “badminton photos”:\n\ndownload_url(search_images('badminton photos', max_images=1)[0], 'badminton.jpg', show_progress=False) # search image returns list of dict, hence we are accessing url in image key\nImage.open('badminton.jpg').to_thumb(256,256)\n\nSearching for 'badminton photos'\n\n\n\n\n\n\n\n\n\nOur searches seem to be giving reasonable results, so let’s grab a few examples of each of “tennis” and “badminton” photos, and save each group of photos to a different folder (I’m also trying to grab a range of lighting conditions here):\n\nsearches = 'badminton','tennis' # this is a tuple not list\npath = Path('tennis_or_not') # thus function gives path which will be used further\nprint(type(path))\n\n&lt;class 'pathlib.PosixPath'&gt;\n\n\n\nfrom time import sleep\n\nfor o in searches:\n    dest = (path/o) # this will append the path with the catagory but the dest will still be pathlib object and not a string\n    dest.mkdir(exist_ok=True, parents=True) # since dest is pathlib obj we can use mkdir directly, by exist_ok=True it does not raise error when the directory already exists.\n    # parents=True will create any parent if needed\n    download_images(dest, urls=search_images(f'{o} photo'))\n    sleep(10)  # Pause between searches to avoid over-loading server\n    download_images(dest, urls=search_images(f'{o} sun photo'))\n    sleep(10)\n    download_images(dest, urls=search_images(f'{o} shade photo'))\n    sleep(10)\n    resize_images(path/o, max_size=400, dest=path/o)\n\nSearching for 'badminton photo'\nSearching for 'badminton sun photo'\nSearching for 'badminton shade photo'\nSearching for 'tennis photo'\nSearching for 'tennis sun photo'\nSearching for 'tennis shade photo'"
  },
  {
    "objectID": "Is_it_a_tennis_Creating_a_model_from_your_own_data.html#step-2-train-our-model",
    "href": "Is_it_a_tennis_Creating_a_model_from_your_own_data.html#step-2-train-our-model",
    "title": "",
    "section": "Step 2: Train our model",
    "text": "Step 2: Train our model\nSome photos might not download correctly which could cause our model training to fail, so we’ll remove them:\n\nfailed = verify_images(get_image_files(path)) # verify function will check if for ach image is it a valid image format of not\nfailed.map(Path.unlink) # It image format is not value then then it is collected in failed list.\n                        # .map will apply the Path.unlink function to all the failed images and delete the failed images\nlen(failed)\n\n9\n\n\nTo train a model, we’ll need DataLoaders, which is an object that contains a training set (the images used to create a model) and a validation set (the images used to check the accuracy of a model – not used during training). In fastai we can create that easily using a DataBlock, and view sample images from it:\n\ndls = DataBlock(\n    blocks=(ImageBlock, CategoryBlock),\n    get_items=get_image_files,\n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=[Resize(192, method='squish')]\n).dataloaders(path, bs=32)\n\ndls.show_batch(max_n=6)\n\n\n\n\n\n\n\n\nHere what each of the DataBlock parameters means:\nblocks=(ImageBlock, CategoryBlock),\nThe inputs to our model are images, and the outputs are categories (in this case, “tennis” or “badminton”).\nget_items=get_image_files,\nTo find all the inputs to our model, run the get_image_files function (which returns a list of all image files in a path).\nsplitter=RandomSplitter(valid_pct=0.2, seed=42),\nSplit the data into training and validation sets randomly, using 20% of the data for the validation set.\nget_y=parent_label,\nThe labels (y values) is the name of the parent of each file (i.e. the name of the folder they’re in, which will be tennis or badminton).\nitem_tfms=[Resize(192, method='squish')]\nBefore training, resize each image to 192x192 pixels by “squishing” it (as opposed to cropping it).\nNow we’re ready to train our model. The fastest widely used computer vision model is resnet18. You can train this in a few minutes, even on a CPU! (On a GPU, it generally takes under 10 seconds…)\nfastai comes with a helpful fine_tune() method which automatically uses best practices for fine tuning a pre-trained model, so we’ll use that.\n\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(10)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n1.435960\n1.422994\n0.483871\n00:00\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.686919\n1.147038\n0.419355\n00:00\n\n\n1\n0.546053\n0.888334\n0.322581\n00:00\n\n\n2\n0.383824\n0.769488\n0.290323\n00:01\n\n\n3\n0.303360\n0.660374\n0.193548\n00:01\n\n\n4\n0.243147\n0.658344\n0.193548\n00:01\n\n\n5\n0.199071\n0.660686\n0.161290\n00:01\n\n\n6\n0.163785\n0.667949\n0.129032\n00:00\n\n\n7\n0.138104\n0.669258\n0.129032\n00:01\n\n\n8\n0.119873\n0.661155\n0.129032\n00:00\n\n\n9\n0.103388\n0.651775\n0.129032\n00:00\n\n\n\n\n\nGenerally when I run this I see 100% accuracy on the validation set (although it might vary a bit from run to run).\n“Fine-tuning” a model means that we’re starting with a model someone else has trained using some other dataset (called the pretrained model), and adjusting the weights a little bit so that the model learns to recognise your particular dataset. In this case, the pretrained model was trained to recognise photos in imagenet, and widely-used computer vision dataset with images covering 1000 categories) For details on fine-tuning and why it’s important, check out the free fast.ai course."
  },
  {
    "objectID": "Is_it_a_tennis_Creating_a_model_from_your_own_data.html#step-3-use-our-model-and-build-your-own",
    "href": "Is_it_a_tennis_Creating_a_model_from_your_own_data.html#step-3-use-our-model-and-build-your-own",
    "title": "",
    "section": "Step 3: Use our model (and build your own!)",
    "text": "Step 3: Use our model (and build your own!)\nLet’s see what our model thinks about that tennis we downloaded at the start:\n\nis_tennis,_,probs = learn.predict(PILImage.create('tennis.jpg'))  # PILImage will return Tensor Image using pillow library\nprint(f\"This is a: {is_tennis}.\")\nprint(f\"Probability it's a tennis: {probs[0]:.4f}\")\n\n\n\n\n\n\n\n\nThis is a: tennis.\nProbability it's a tennis: 0.0002\n\n\nGood job, resnet18. :)\nSo, as you see, in the space of a few years, creating computer vision classification models has gone from “so hard it’s a joke” to “trivially easy and free”!\nIt’s not just in computer vision. Thanks to deep learning, computers can now do many things which seemed impossible just a few years ago, including creating amazing artworks, and explaining jokes. It’s moving so fast that even experts in the field have trouble predicting how it’s going to impact society in the coming years.\nOne thing is clear – it’s important that we all do our best to understand this technology, because otherwise we’ll get left behind!\nNow it’s your turn. Click “Copy & Edit” and try creating your own image classifier using your own image searches!\nIf you enjoyed this, please consider clicking the “upvote” button in the top-right – it’s very encouraging to us notebook authors to know when people appreciate our work."
  }
]